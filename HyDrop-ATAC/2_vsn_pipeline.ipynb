{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial assumes that the HyDrop fastq files have been placed in a directory `fastq/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-1_S1_R1.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-1_S1_R2.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-1_S1_R3.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-2_S2_R1.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-2_S2_R2.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-2_S2_R3.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-3_S3_R1.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-3_S3_R2.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-3_S3_R3.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-4_S4_R1.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-4_S4_R2.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-4_S4_R3.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-5_S5_R1.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-5_S5_R2.fastq.gz\u001b[0m\n",
      "\u001b[01;32mfastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-5_S5_R3.fastq.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls fastq/HYA*R?.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hydrop-rna library looks like this:\n",
    "\n",
    "```\n",
    "               Index 1: i7 read 10 bp           Read 1: cDNA read 86 bp (R1)\n",
    "\n",
    "             <- HyDrop_CustSeq_Short_i7_Read            <- NXT               \n",
    "|-5’-[P7]-[i7]-[HyDrop_CustSeq_Short]-[BC_UMI]-[polyA]-[cDNA]-[NXT]-[i5]-[P5]-3’\n",
    "  3’-[P7]-[i7]-[HyDrop_CustSeq_Short]-[BC_UMI]-[polyT]-[cDNA]-[NXT]-[i5]-[P5]-5’-|  \n",
    "                HyDrop_CustSeq_Short ->                    NXT ->    \n",
    "                \n",
    "                   Read 2: BC 60 bp  (R2)           Index 2: i5 read 10 bp       \n",
    "\n",
    "```\n",
    "\n",
    "And a HyDrop-ATAC library looks like so:\n",
    "\n",
    "```\n",
    "                                Index 1: BC read  (R2)     Read 1: ATAC mate 1  (R1)\n",
    "\n",
    "                                         <- Tn5       <- Tn5               \n",
    "|-5’-[P7]-[i7]-[HyDrop_CustSeq_Short]-[BC]-[Tn5]-[gDNA]-[Tn5]-[i5]-[P5]-3’\n",
    "  3’-[P7]-[i7]-[HyDrop_CustSeq_Short]-[BC]-[Tn5]-[gDNA]-[Tn5]-[i5]-[P5]-5’-|  \n",
    "                                            Tn5 ->       Tn5 ->    \n",
    "                \n",
    "                               Read 2: ATAC mate 2 (R3)   Index 2: i5 read 10 bp       \n",
    "\n",
    "```\n",
    "\n",
    "The barcode read is ultimately structured like this for both protocols:\n",
    "\n",
    "```\n",
    "-[BC1]-[AD1]-[BC2]-[AD2]-[BC3]-[UMI]\n",
    "-[10b]-[10b]-[10b]-[10b]-[10b]-[8bp]\n",
    "```\n",
    "\n",
    "With the lengths of each part under the part.\n",
    "The adapters inbetween the 3 sub-barcodes are identical for all reads.\n",
    "We must cut those out first and write a \"BCONLY\" (barcode only) fastq file.\n",
    "We use (M)AWK for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load mawk\n",
    "\n",
    "split_fastq (){\n",
    "    local input_fastq_filename=\"${1}\";\n",
    "    local output_fastq_split1_filename=\"${2}\";\n",
    "    local split1_start=1;\n",
    "    local split1_end=10;\n",
    "    local split2_start=21;\n",
    "    local split2_end=30;\n",
    "    local split3_start=41;\n",
    "    local split3_end=50;\n",
    "    zcat \"${input_fastq_filename}\" \\\n",
    "      | mawk \\\n",
    "            -v \"split1_start=${split1_start}\" \\\n",
    "            -v \"split1_end=${split1_end}\" \\\n",
    "            -v \"split2_start=${split2_start}\" \\\n",
    "            -v \"split2_end=${split2_end}\" \\\n",
    "            -v \"split3_start=${split3_start}\" \\\n",
    "            -v \"split3_end=${split3_end}\" \\\n",
    "            -v \"output_fastq_split1_filename=${output_fastq_split1_filename}\" \\\n",
    "            '\n",
    "            BEGIN {\n",
    "                split1_length = split1_end - split1_start + 1;\n",
    "                split2_length = split2_end - split2_start + 1;\n",
    "                split3_length = split3_end - split3_start + 1;\n",
    "            }\n",
    "            {\n",
    "                if (NR % 2 == 1) {\n",
    "                    # Read name or \"+\" line.\n",
    "                    print $0 > output_fastq_split1_filename\n",
    "                } else {\n",
    "                    # Sequence or quality line.\n",
    "                    print substr($0, split1_start, split1_length) substr($0, split2_start, split2_length) substr($0, split3_start, split3_length) > output_fastq_split1_filename;\n",
    "                }\n",
    "            }'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-1_S1_R2.BCONLY.fastq\n",
      "[11] 3909\n",
      "fastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-2_S2_R2.BCONLY.fastq\n",
      "[12] 3910\n",
      "fastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-3_S3_R2.BCONLY.fastq\n",
      "[13] 3911\n",
      "fastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-4_S4_R2.BCONLY.fastq\n",
      "[14] 3914\n",
      "fastq/HYA__combined__20210323_cortex_phu_dv_etssb_1-5_S5_R2.BCONLY.fastq\n",
      "[15] 3917\n"
     ]
    }
   ],
   "source": [
    "for fastq in fastq/*combined*S?_R2.fastq.gz\n",
    "do\n",
    "    newname=${fastq%.fastq.gz}.BCONLY.fastq\n",
    "    echo $newname\n",
    "    split_fastq $fastq $newname &\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress the resulting BCONLY fastq files. You can also pipe the MAWK output directly to gzip or pigz, but I often like to inspect the fastq files before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 4547\n",
      "[2] 4548\n",
      "[3] 4549\n",
      "[4] 4550\n",
      "[5] 4551\n"
     ]
    }
   ],
   "source": [
    "module load pigz\n",
    "for fastq in fastq/*BCONLY.fastq\n",
    "do\n",
    "    pigz -p 6 $fastq &\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the VSN pipeline to perform barcode correction, map to a reference genome and generate fragments files.\n",
    "First, we must make a metadata file as described in the VSN documentation. The script below automates this step so no copy/pasting errors are made.\n",
    "Make sure that you use the bconly files in vsn pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm metadata_auto.tsv\n",
    "dir=`pwd -P`\n",
    "echo -e 'sample_name\\ttechnology\\tfastq_PE1_path\\tfastq_barcode_path\\tfastq_PE2_path' > metadata_auto.tsv\n",
    "for fastq in fastq/*combined*S?_R2.fastq.gz\n",
    "do\n",
    "    samplename=${fastq%_R2.fastq.gz}\n",
    "    metadatasamplename=${samplename#fastq/}\n",
    "    R1=$dir/${samplename}_R1.fastq.gz\n",
    "    R2=$dir/${samplename}_R2.BCONLY.fastq.gz\n",
    "    R3=$dir/${samplename}_R3.fastq.gz\n",
    "    echo -e $metadatasamplename'\\tstandard\\t'$R1'\\t'$R2'\\t'$R3 >> metadata_auto.tsv\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we must generate a config file to configure the VSN pipeline parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) Java/1.8.0_162 => Java/1.8.0\n",
      "\n",
      "Checking vib-singlecell-nf/vsn-pipelines ...\n",
      " Already-up-to-date - revision: 68397367f7 [develop_atac]\n"
     ]
    }
   ],
   "source": [
    "module load graphviz\n",
    "module load Nextflow\n",
    "nextflow pull vib-singlecell-nf/vsn-pipelines -r develop_atac\n",
    "\n",
    "nextflow config \\\n",
    "    vib-singlecell-nf/vsn-pipelines/main_atac.nf \\\n",
    "    -profile atac_preprocess,singularity \\\n",
    "    > atac_preprocess.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must make some important changes to the config file:\n",
    "* Redirect the config file to metadata_auto.tsv instead of standard metadata.tsv\n",
    "* If you use multispecies bwa index, make sure to edit the sinto regex for which fragments to accept! Try with '\"(?i)^GRCh38_chr|(?i)^mm10\"'. Generally, this regex should allow all the chromosomes which you want to be included in the final fragments file.\n",
    "* Change the bwa executor to local if you want the job to start immediately. Otherwise, you can keep the PBS job submission system in place.\n",
    "* Number of CPUs for BWA: better to have 2 forks running with 17 threads than to have 1 fork with 36 threads due to I/O overhead\n",
    "* Change the bwa index directory to the right one!\n",
    "* Add whitelist path under 'standard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run in a new tmux session (to prevent interruption):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextflow -C atac_preprocess.config run \\\n",
    "    vib-singlecell-nf/vsn-pipelines/main_atac.nf \\\n",
    "    -entry atac_preprocess -r develop_atac -resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the run has finished, copy the fragments files to a new dir `fragments/`. This ensures that if you accidentally modify or delete the fragments files, you still have a backup and don't need to re-run the fragments file generation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘fragments/’: File exists\n"
     ]
    }
   ],
   "source": [
    "mkdir fragments/\n",
    "cp out/data/fragments/* fragments/\n",
    "cp out/data/bam/*mapping_stats.tsv fragments/\n",
    "cp out/data/fastq/*.corrected.bc_stats.tsv fragments/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also like uncompressed copies of the fragments files at hand for easy inspection and modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragments/HYA__932b0e__20210309_mouse_cortex_MCF-7_PC3_1-1_S2.sinto.fragments.NONEGS.tsv\n",
      "[1] 36310\n",
      "fragments/HYA__932b0e__20210309_mouse_cortex_MCF-7_PC3_1-1_S2.sinto.fragments.tsv\n",
      "[2] 36311\n",
      "fragments/HYA__af8d60__20210309_mouse_cortex_MCF-7_PC3_1-2_S3.sinto.fragments.NONEGS.tsv\n",
      "[3] 36312\n",
      "fragments/HYA__af8d60__20210309_mouse_cortex_MCF-7_PC3_1-2_S3.sinto.fragments.tsv\n",
      "[4] 36313\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-1_S1.sinto.fragments.tsv\n",
      "[5] 36314\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-2_S2.sinto.fragments.tsv\n",
      "[6] 36315\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-3_S3.sinto.fragments.tsv\n",
      "[7] 36316\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-4_S4.sinto.fragments.tsv\n",
      "[8] 36317\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-5_S5.sinto.fragments.tsv\n",
      "[9] 36318\n"
     ]
    }
   ],
   "source": [
    "for file in fragments/*.gz\n",
    "do\n",
    "    newname=${file%.gz}\n",
    "    echo $newname\n",
    "    /vsc-hard-mounts/leuven-data/software/biomed/skylake_centos7/2018a/software/zlib-ng/2.0.1-foss-2018a/bin/zlib_ng.sh zcat $file > $newname &\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, especially on chrM, sinto can generate negative coordinates for fragments close to the edge of the chromosome. This can give problems with some tools which use fragments files. Therefore, we replace all negative start positions by zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragments/HYA__932b0e__20210309_mouse_cortex_MCF-7_PC3_1-1_S2.sinto.fragments.tsv\n",
      "[1] 36508\n",
      "fragments/HYA__af8d60__20210309_mouse_cortex_MCF-7_PC3_1-2_S3.sinto.fragments.tsv\n",
      "[2] 36509\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-1_S1.sinto.fragments.tsv\n",
      "[3] 36510\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-2_S2.sinto.fragments.tsv\n",
      "[4] 36511\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-3_S3.sinto.fragments.tsv\n",
      "[5] 36512\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-4_S4.sinto.fragments.tsv\n",
      "[6] 36513\n",
      "fragments/HYA__combined__20210323_cortex_phu_dv_etssb_1-5_S5.sinto.fragments.tsv\n",
      "[7] 36514\n"
     ]
    }
   ],
   "source": [
    "module load mawk\n",
    "for tsv in fragments/*.sinto.fragments.tsv\n",
    "do\n",
    "    echo $tsv\n",
    "    newname=${tsv%.tsv}.NONEGS.tsv\n",
    "    mawk -v OFS='\\t' -F '\\t' '$2 ~ /^-/ {$2=1}1' $tsv > $newname &\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bgzip the uncompressed `NONEGS` fragments files. As stated before, you can pipe these commands, but I like to inspect inbetween steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) XZ/5.2.3-GCCcore-6.4.0 => XZ/5.2.4-GCCcore-6.4.0\n",
      "  2) bzip2/1.0.6-GCCcore-6.4.0 => bzip2/1.0.8-GCCcore-6.4.0\n",
      "\n",
      "[1] 36784\n",
      "[2] 36785\n",
      "[3] 36786\n",
      "[4] 36787\n",
      "[5] 36788\n",
      "[6] 36789\n",
      "[7] 36790\n"
     ]
    }
   ],
   "source": [
    "module load BCFtools\n",
    "for tsv in fragments/*.sinto.fragments.NONEGS.tsv\n",
    "do\n",
    "    bgzip -@ 6 $tsv &\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have species-mixed data, you can already separate fragments mapping to either species from the other. This of course depends on the index (chromosome names) that you used to map. Below, is a command I use if I want to do this for mouse and human data. Since we are currently analysing mouse data only, it is not necessary. In fact, it won't do anything as none of the chromosome names start with `mm10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragments/HYA__665d2b__20210323_cortex_phu_dv_etssb_1-1_S1\n",
      "[1] 35032\n",
      "[2] 35035\n",
      "fragments/HYA__8aaaff__20210323_cortex_phu_dv_etssb_1-2_S2\n",
      "[3] 35038\n",
      "[4] 35041\n",
      "fragments/HYA__932b0e__20210309_mouse_cortex_MCF-7_PC3_1-1_S2\n",
      "[5] 35044\n",
      "[6] 35047\n",
      "fragments/HYA__a64416__20210323_cortex_phu_dv_etssb_1-3_S3\n",
      "[7] 35050\n",
      "[8] 35053\n",
      "fragments/HYA__af8d60__20210309_mouse_cortex_MCF-7_PC3_1-2_S3\n",
      "[9] 35056\n",
      "[10] 35059\n",
      "fragments/HYA__b8797a__20210323_cortex_phu_dv_etssb_1-4_S4\n",
      "[11] 35062\n",
      "[12] 35065\n",
      "fragments/HYA__f1116e__20210323_cortex_phu_dv_etssb_1-5_S5\n",
      "[13] 35068\n",
      "[14] 35071\n"
     ]
    }
   ],
   "source": [
    "module loads BCFtools\n",
    "for frags in fragments/*.tsv.gz\n",
    "do\n",
    "    # echo $frags\n",
    "    newname=${frags%.sinto.fragments.tsv.gz}\n",
    "    echo $newname\n",
    "    zgrep ^mm10 $frags | sed 's/^mm10_//g' | bgzip -c > $newname.sinto.fragments.MM10.gz &\n",
    "    zgrep ^GRCh38 $frags | sed 's/^GRCh38_//g' | bgzip -c > $newname.sinto.fragments.GRCH38.gz &\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
